{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/victoregomezf-maker/Taller4/blob/main/Taller4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Taller 4: De Regresión Lineal a Machine Learning**\n"
      ],
      "metadata": {
        "id": "6miIwpc_R9y6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Preguntas cortas:**\n",
        "\n",
        "**1.** Entrenas un modelo y obtienes un 99% de exactitud sobre los datos de entrenamiento, pero solo un 75% sobre los datos de prueba. ¿Qué problema indica este resultado y por qué?\n",
        "\n",
        "\n",
        "**2.** Si el error de tu modelo es muy alto tanto en el conjunto de entrenamiento como en el de validación, ¿cuál es el problema más probable? ¿Creerías que añadir más datos de entrenamiento solucionaría el problema?"
      ],
      "metadata": {
        "id": "B_r_ggknS7Yl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Solución**\n",
        "\n",
        "**1.**  Esto refleja un problema de **sobreajuste (overfitting).** El modelo muestra un rendimiento casi perfecto en entrenamiento, pero falla al generalizar a datos nuevos, porque en lugar de aprender patrones generales, se quedó “pegado” a los detalles y al ruido del conjunto de entrenamiento.\n",
        "\n",
        "**Ejemplo práctico:** es como un estudiante que memoriza las respuestas de un simulacro y saca 10 en él, pero al cambiarle un poco las preguntas en el examen real, solo obtiene 7,5.\n",
        "\n",
        "**Causas principales:** modelo demasiado complejo, exceso de variables, falta de regularización.\n",
        "\n",
        "**Posibles soluciones:**\n",
        "\n",
        "Aplicar técnicas de regularización (Lasso, Ridge).\n",
        "\n",
        "Reducir la complejidad del modelo.\n",
        "\n",
        "Ampliar la diversidad de datos de entrenamiento para mejorar la capacidad de generalización.\n",
        "\n",
        "**2.** El escenario corresponde a **subajuste (underfitting)**, lo que significa que el modelo no tiene la capacidad de aprender los patrones de los datos.\n",
        "\n",
        "**Señal clave:** error alto en entrenamiento y validación.\n",
        "\n",
        "**¿Agregar más datos ayuda?** No, porque el problema es de capacidad del modelo, no de cantidad de datos.\n",
        "\n",
        "**Posibles soluciones:**\n",
        "\n",
        "Incrementar la complejidad del modelo (por ejemplo, usar árboles más profundos o modelos no lineales).\n",
        "\n",
        "Incluir nuevas variables (features) más relevantes.\n",
        "\n",
        "Disminuir la regularización si es muy estricta.\n",
        "\n",
        "Aumentar el tiempo de entrenamiento o número de épocas."
      ],
      "metadata": {
        "id": "O5OvmolETUTK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Regularización Ridge y Lasso**"
      ],
      "metadata": {
        "id": "WXB0_Q1X56k_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Preguntas cortas:**\n",
        "\n",
        "1. En un problema para predecir fallas en una máquina, tienes 100 variables provenientes de sensores, pero sospechas que solo unas pocas son realmente importantes. ¿Usarías Ridge o Lasso? Justifica tu respuesta.\n",
        "\n",
        "2. Si entrenas un modelo Lasso y aumentas gradualmente el valor del hiperparámetro de penalización (λ), ¿qué efecto esperarías observar en los coeficientes del modelo?\n",
        "\n",
        "3. Al ejecutar el código de regularización 3D, ¿qué sucede con los coeficientes del modelo a medida que aumenta el valor de λ? ¿Qué interpretación le das a la forma diferente en que Ridge y Lasso aplican sus penalizaciones?"
      ],
      "metadata": {
        "id": "0R2xwijVVrVw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Solución**\n",
        "1. La técnica más conveniente es **Lasso**, porque:\n",
        "\n",
        "Reduce la magnitud de los coeficientes y puede llevar algunos a cero.\n",
        "\n",
        "Elimina de manera automática las variables irrelevantes.\n",
        "\n",
        "Favorece la interpretación del modelo al quedarse solo con las variables más importantes.\n",
        "\n",
        "Es especialmente útil en un entorno industrial con sensores redundantes, porque ayuda a identificar qué sensores son realmente determinantes para predecir fallas.\n",
        "\n",
        "\n",
        "En cambio, **Ridge** solo reduce los valores, pero nunca elimina variables, lo que dificulta el filtrado de las no relevantes.\n",
        "\n",
        "2. **Si λ se incrementa:**\n",
        "\n",
        "**1.** Los coeficientes disminuyen gradualmente en magnitud.\n",
        "\n",
        "**2.** Algunos coeficientes se vuelven exactamente cero, lo que elimina variables.\n",
        "\n",
        "**3.** Con un λ muy alto, el modelo puede terminar sin variables activas.\n",
        "Este proceso es útil para seleccionar solo las variables relevantes y evitar que el modelo se complique innecesariamente.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "3. Cuando se incrementa el valor de λ, ambos métodos de regularización reducen la magnitud de los coeficientes, pero lo hacen de manera distinta:\n",
        "\n",
        "**Ridge (penalización L2):**\n",
        "\n",
        "Los coeficientes se reducen de forma proporcional.\n",
        "\n",
        "Ningún coeficiente llega exactamente a cero.\n",
        "\n",
        "Es útil cuando se sospecha que todas las variables aportan algo de información, aunque sea poco.\n",
        "\n",
        "Geométricamente, la restricción tiene forma de círculo/esfera, lo que distribuye la reducción de manera uniforme.\n",
        "\n",
        "**Lasso (penalización L1):**\n",
        "\n",
        "Aumentar λ fuerza a que varios coeficientes se vuelvan exactamente cero.\n",
        "\n",
        "Esto implica una selección automática de variables, eliminando aquellas menos relevantes.\n",
        "\n",
        "Es muy valioso cuando hay muchas variables irrelevantes y se busca simplicidad e interpretabilidad.\n",
        "\n",
        "Geométricamente, la restricción tiene forma de rombo/poliedro, lo que hace más probable que la solución caiga en un vértice (donde algunos coeficientes son cero).\n",
        "\n",
        "**Interpretación práctica:**\n",
        "\n",
        "**Ridge:** “ajusta el volumen de todas las perillas de un ecualizador, bajando todas un poco pero sin apagar ninguna”.\n",
        "\n",
        "**Lasso** “apaga directamente algunas perillas (variables) y deja encendidas solo las que importan”."
      ],
      "metadata": {
        "id": "YmMp27CpWp4r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Optimización con GridSearchCV**"
      ],
      "metadata": {
        "id": "0Qi9SZEC8Oxf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Preguntas cortas:**\n",
        "1. Quieres optimizar un modelo Ridge y pruebas manualmente alpha=10, obteniendo un buen resultado. ¿Por qué sigue siendo metodológicamente superior usar GridSearchCV en lugar de quedarte con ese valor?\n",
        "\n",
        "2. Además del modelo en sí (ej. Lasso()), ¿cuáles son los dos componentes principales que debes proporcionar a GridSearchCV para iniciar la búsqueda de hiperparámetros?\n",
        "\n",
        "3. Si GridSearchCV selecciona un alpha muy pequeño (cercano a cero) como el mejor parámetro para tu modelo, ¿qué te sugiere esto sobre el nivel de sobreajuste que tenía tu modelo original sin regularizar?"
      ],
      "metadata": {
        "id": "VlspjRQwYmO4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Solución:**\n",
        "Aunque probar manualmente un valor de α=10 parezca suficiente, el uso de GridSearchCV es metodológicamente superior por razones fundamentales:\n",
        "\n",
        "**1.Exploración completa del espacio de parámetros:** GridSearchCV prueba una gama de valores posibles de α (u otros hiperparámetros), asegurando que la búsqueda sea exhaustiva y no se limite a una elección casual.\n",
        "\n",
        "**2.Uso de validación cruzada (cross-validation):** evalúa el rendimiento del modelo en diferentes subconjuntos de los datos, proporcionando una estimación más precisa y estable del desempeño real.\n",
        "\n",
        "**3.Evita sesgos de selección:** probar manualmente un solo valor puede generar una falsa sensación de buen rendimiento, influenciado por el azar o las particularidades del conjunto de validación.\n",
        "\n",
        "**4.Mayor rigor y reproducibilidad:** GridSearchCV sigue un proceso estructurado, eliminando decisiones subjetivas o empíricas.\n",
        "\n",
        "**5.Garantía de encontrar el mejor punto:** incluso si α=10 ofrece buenos resultados, el método puede identificar un valor óptimo (por ejemplo, α=8.7) que maximice la capacidad de generalización del modelo.\n",
        "\n",
        "2. Para ejecutar correctamente una búsqueda de hiperparámetros con GridSearchCV, se requieren dos elementos esenciales además del modelo:\n",
        "\n",
        "**1.param_grid (rejilla de parámetros):** un diccionario que define qué hiperparámetros se desean evaluar y los valores que tomará cada uno.\n",
        "\n",
        "Ejemplo:\n",
        "\n",
        "param_grid = {'alpha': [0.1, 1, 10, 100], 'solver': ['svd', 'cholesky']}\n",
        "\n",
        "\n",
        "Esto indica que GridSearchCV probará combinaciones de estos valores hasta encontrar las que produzcan el mejor rendimiento.\n",
        "\n",
        "**2.cv (cross-validation):** número de divisiones del conjunto de datos para la validación cruzada. Por ejemplo, cv=5 divide los datos en cinco subconjuntos, entrenando con cuatro y validando con uno distinto en cada iteración.\n",
        "\n",
        "Estos dos componentes garantizan que la búsqueda de parámetros se realice de forma ordenada, controlada y confiable, evitando que el modelo dependa de resultados azarosos.\n",
        "\n",
        "3. Si el mejor valor que selecciona GridSearchCV es un α muy cercano a cero, significa que el modelo no requería una regularización fuerte para generalizar correctamente.\n",
        "Esto sugiere que el modelo original ya se encontraba en un punto de equilibrio entre sesgo y varianza, es decir:\n",
        "\n",
        "No presentaba **sobreajuste (overfitting)** porque no estaba memorizando los datos de entrenamiento.\n",
        "\n",
        "No sufría **subajuste (underfitting)** porque su complejidad era suficiente para captar los patrones existentes.\n",
        "\n",
        "**Interpretación:**\n",
        "Un α pequeño implica una penalización mínima, lo que confirma que los coeficientes pueden conservar su magnitud original sin comprometer el desempeño.\n",
        "\n",
        "**Consecuencia práctica:**\n",
        "Aplicar una regularización más alta en este caso haría que el modelo perdiera información útil, aumentando el error.\n",
        "\n",
        "**Ejemplo:**\n",
        "En un modelo que predice el consumo energético de una planta, un α cercano a 0 indica que las relaciones entre las variables ya estaban bien definidas, sin necesidad de penalizar sus pesos."
      ],
      "metadata": {
        "id": "6sRqvzCbZdxk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Construir un Árbol de Decisión: El Diagrama de Flujo Inteligente para la Optimización de Procesos**\n"
      ],
      "metadata": {
        "id": "D4R45syEbDkf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Preguntas cortas:**\n",
        "1. En un árbol de decisión para optimizar la logística de un almacén, ¿qué podría representar un nodo hoja?\n",
        "\n",
        "2. Un ingeniero crea un árbol para predecir fallos en una máquina. El árbol es extremadamente profundo y tiene reglas muy específicas como \"Si la temperatura es 75.3°C y la vibración es 0.152 m/s² y el operador es Juan...\". ¿Qué problema de ajuste es este y por qué no sería fiable en la práctica diaria de la planta?"
      ],
      "metadata": {
        "id": "DaQ51T5sbRHZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Solución:**\n",
        "1. En un árbol de decisión, un nodo hoja representa el resultado final de la clasificación o la predicción, es decir, el punto donde termina la ruta de decisiones.\n",
        "\n",
        "En un modelo para optimizar la logística de un almacén, un nodo hoja podría corresponder a decisiones como:\n",
        "\n",
        "**1.**“Ubicar el producto en el pasillo 3, zona A”.\n",
        "\n",
        "**2.**“Enviar el pedido por transporte terrestre”.\n",
        "\n",
        "**3.**“Asignar la orden al operario X”.\n",
        "Cada hoja se alcanza tras evaluar una secuencia de condiciones (por ejemplo, tipo de producto → tamaño → nivel de demanda). Una vez llegamos al nodo hoja, no se aplican más divisiones: el modelo emite su decisión o categoría final.\n",
        "\n",
        "2. El caso descrito corresponde a un **sobreajuste (overfitting)**.\n",
        "El árbol de decisión se ha vuelto demasiado complejo y ha aprendido los valores exactos de los datos de entrenamiento, en lugar de capturar tendencias generales.\n",
        "\n",
        "**Por qué no es confiable:**\n",
        "\n",
        "**1.** Las reglas son excesivamente precisas (temperaturas y vibraciones con decimales exactos).\n",
        "\n",
        "**2.** Es poco probable que esas condiciones se repitan exactamente en la realidad.\n",
        "\n",
        "**3.** Factores irrelevantes (como el nombre del operador) se incluyen en las reglas, aumentando el ruido.\n",
        "\n",
        "**4.** En la práctica, pequeñas variaciones de condiciones (por ejemplo, 75.4°C) harían que el árbol no reconozca la situación.\n",
        "\n",
        "**Consecuencia:** el modelo falla con nuevos datos, ya que está “memorizando” en lugar de aprender.\n",
        "\n",
        "**Solución:** aplicar poda (pruning), limitar la profundidad (max_depth), o ajustar parámetros como min_samples_split para forzar que el modelo aprenda reglas más generales y útiles.\n",
        "\n",
        "**Ejemplo:**\n",
        "Un árbol que clasifica “Falla” si la temperatura es exactamente 75.3°C fallará cuando el sensor marque 75.2°C, aunque el contexto sea el mismo."
      ],
      "metadata": {
        "id": "m4K16GdAbqmA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Preguntas cortas:**\n",
        "1. Al visualizar la \"importancia de las características\" de tu árbol, descubres que el \"proveedor de materia prima\" es la variable más importante. ¿Qué acción inmediata podrías tomar en la planta con esta información?\n",
        "\n",
        "2. Si tu árbol de decisión está clasificando perfectamente los datos históricos pero falla mucho con los datos de la última semana (sobreajuste), ¿qué parámetro de poda ajustarías primero para que generalice mejor?"
      ],
      "metadata": {
        "id": "vWYFEjizcyFb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Solución:**\n",
        "1. Identificar que el proveedor de materia prima es la variable más importante permite tomar medidas directas para mejorar la calidad y eficiencia del proceso productivo.\n",
        "\n",
        "**Acciones inmediatas recomendadas:**\n",
        "\n",
        "**1. Auditar proveedores:** revisar la trazabilidad, puntualidad y calidad del material que cada proveedor entrega.\n",
        "\n",
        "**2. Implementar controles de recepción:** realizar pruebas de calidad a las materias primas antes de incorporarlas al proceso.\n",
        "\n",
        "**3. Estandarizar especificaciones técnicas:** definir criterios mínimos de calidad y exigir su cumplimiento.\n",
        "\n",
        "**4. Optimizar relaciones comerciales:** priorizar proveedores confiables y renegociar contratos con aquellos que generen más desperdicio o fallas.\n",
        "\n",
        "**5. Monitorear el impacto:** llevar un registro comparativo de defectos por proveedor para medir mejoras.\n",
        "\n",
        "**Ejemplo:**\n",
        "Si el modelo muestra que el proveedor “A” está vinculado al 70% de los rechazos de calidad, la acción inmediata sería revisar sus lotes y reemplazarlo si es necesario.\n",
        "\n",
        "2. El primer parámetro que se debe ajustar es la profundidad máxima del árbol (max_depth), ya que controla directamente la complejidad del modelo.\n",
        "\n",
        "**Justificación:**\n",
        "\n",
        "El parámetro más adecuado para ajustar primero es max_depth, ya que controla directamente la complejidad del árbol y permite reducir el sobreajuste. Cuando el árbol crece demasiado, comienza a aprender detalles y variaciones mínimas de los datos de entrenamiento, generando reglas excesivamente específicas que no se repiten en los nuevos casos. Al limitar su profundidad, el modelo se ve obligado a construir divisiones más generales, capturando patrones globales y no excepciones. Esto mejora la capacidad de generalización, evita que el modelo dependa del ruido y mantiene una estructura más interpretable. Por ello, ajustar max_depth es la forma más directa y efectiva de equilibrar precisión y robustez en un árbol de decisión."
      ],
      "metadata": {
        "id": "H-cQ9VY0dJTt"
      }
    }
  ]
}